{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f94789ec-5081-4692-bde2-aa5869467b9c",
   "metadata": {},
   "source": [
    "# Module 20 - Transparency and Interpretability\n",
    "\n",
    "## Module Overview\n",
    "\n",
    "During this programme, you have learned about a wide range of machine learning methods as well as about their potential applications and advantages for solving data-based problems. But you have only scratched the surface on the unintended consequences that can occur when data, or the model itself, have pre-existing biases baked in. This module covers several strategies for improving the transparency and interpretability of models so that biases can be more easily recognised and taken into consideration when analysing a model’s results.\n",
    "\n",
    "## Learning outcomes\n",
    "\n",
    "- LO 1: Define transparency and interpretability.\n",
    "- LO 2: Recognise bias inherent in data.\n",
    "- LO 3: Develop a datasheet for a data set.\n",
    "- LO 4: Recognise bias in the creation of machine learning models.\n",
    "- LO 5: Identify ways to benchmark models against reporting standards.\n",
    "- LO 6: Identify trade-offs between explainability or interpretability.\n",
    "- LO 7: Build an interpretable decision tree.\n",
    "- LO 8: Refine a codebase for machine learning competitions.\n",
    "\n",
    "## Module Summary Description\n",
    "\n",
    "This module explores the critical concepts of transparency and interpretability in machine learning. As models increasingly influence real-world decisions, understanding their inner workings and the data they rely on is essential. The module highlights how machine learning systems can unintentionally reinforce bias, particularly when trained on historical or unbalanced data. Through real-world case studies, such as biased recruitment algorithms and wrongful arrests due to facial recognition errors, learners examine the ethical consequences of opaque model behavior.\n",
    "\n",
    "To mitigate these risks, the module introduces tools like Datasheets for Datasets and Model Cards, which improve documentation, transparency, and accountability. Learners also explore methods to detect and reduce bias in data and models, and build interpretable models—such as decision trees—that offer human-understandable reasoning. The module concludes with a comparison between Explainable AI (post hoc interpretation of complex models) and Interpretable AI (models that are inherently transparent), emphasising the trade-offs between model complexity and human comprehension.\n",
    "\n",
    "Additional Reading: https://excavating.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2d94ea-a3ba-4b16-a3b2-2313104e2ed1",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "As we deploy machine learning in real-world settings, we must ask critical questions: \n",
    "- Why did the model make the decision it made?\n",
    "- Is the model aligned with our ethical and societal values?\n",
    "- Is the model robust, or is it vulnerable to adversarial manipulation?\n",
    "\n",
    "In addition, it is essential to understand and comply with regulatory standards, particularly the UK General Data Protection Regulation (UK GDPR), which emphasises individuals' rights to explanation and fairness in automated decision-making.\n",
    "\n",
    "## Consequences of bad ML predictions\n",
    "\n",
    "- **Discrimination and bias**: Machine learning models can unintentionally encode and reinforce societal biases, particularly around race, gender, and other protected characteristics.\n",
    "- **Case study – wrongful arrest**: In 2020, the first publicly known case of faulty facial recognition led to the wrongful arrest of an innocent man, highlighting the real-world dangers of biased models in high-stakes scenarios like law enforcement.\n",
    "- **Case study – Amazon recruitment tool**: Amazon developed a recruitment algorithm that penalised CVs containing the word “woman” or references to all-women colleges. This occurred because the system had learned from historical hiring patterns, which were themselves biased.\n",
    "\n",
    "These examples demonstrate the importance of scrutinising both the training data and model behavior before deployment, especially in contexts where fairness and ethics are critical\n",
    "\n",
    "## Data-related issues and how to address them\n",
    "\n",
    "**Undersampled populations**: When certain groups are underrepresented in training data (e.g. fewer Black faces than white faces in a facial recognition dataset), models may perform poorly on those groups.\n",
    "\n",
    "*Solution*: Augment the dataset with more diverse examples or apply data balancing techniques during training.\n",
    "  \n",
    "**Embedded perspectives**: Bias can be introduced through subjective choices during data annotation or collection, such as the assumptions of annotators or framing of questions.\n",
    "\n",
    "*Solution*: Use diverse annotation teams, clear guidelines, and audit processes to reduce unintentional bias.\n",
    "\n",
    "**Lack of transparency in dataset provenance**: Without context about how data was gathered, used, and annotated, it's difficult to evaluate potential sources of bias or ethical concerns.\n",
    "\n",
    "*Solution*: Adopt Datasheets for Datasets. This is a documentation framework that captures important metadata about datasets, including motivation, composition, collection methodology, potential uses, and ethical considerations.\n",
    "\n",
    "Datasheets for Datasets (Gebru et al., 2018) https://arxiv.org/abs/1803.09010. This influential paper proposes a standardised way to document datasets, promoting transparency, reproducibility, and accountability in machine learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a236fe-ae28-424a-b36f-9a0ab1b17d80",
   "metadata": {},
   "source": [
    "## Recognising bias in models\n",
    "\n",
    "When developing or deploying machine learning models, it's crucial to consider the perspectives and responsibilities of various stakeholders involved:\n",
    "- ML and AI practitioners – Evaluate model performance, monitor fairness metrics, and identify bias during development.\n",
    "- Model developers – Make design choices about training data, algorithms, and model architecture, all of which influence outcomes.\n",
    "- Software developers – Integrate model predictions into applications and systems; must understand the model’s limitations.\n",
    "- Policy makers – Assess how a model may impact different groups in society, especially with regard to fairness, transparency, and compliance.\n",
    "- Organisations – Decide whether to adopt ML technologies, considering ethical, reputational, and legal implications.\n",
    "- Affected individuals – Have the right to understand how a model works, particularly if it influences their lives (e.g. hiring, lending, law enforcement).\n",
    "\n",
    "**Model cards** are a documentation framework designed to improve transparency and accountability in machine learning models. Much like Datasheets for Datasets, model cards aim to provide essential information that helps stakeholders understand when and how a model should (or should not) be used.\n",
    "\n",
    "They help reduce the risk of inappropriate deployment by clearly stating the model’s capabilities, limitations, and ethical considerations.\n",
    "\n",
    "A standard model card typically includes: \n",
    "- Intended uses – What the model is designed for, and what it is not intended for.\n",
    "- Relevant factors – Characteristics (e.g., demographic, environmental) that may affect model performance.\n",
    "- Metrics – The quantitative performance measures used to evaluate the model (e.g., accuracy, precision, fairness).\n",
    "- Training data – Information about the data used to train the model, including sources and potential biases.\n",
    "- Evaluation data – Details of datasets used to test the model, and their similarity to real-world use cases.\n",
    "- Quantitative analysis – Results broken down by different subgroups (e.g., race, gender) to identify potential disparities.\n",
    "- Ethical considerations – Potential risks, unintended uses, and steps taken to mitigate harm.\n",
    "- Model details – Technical specifications, such as algorithm type, version, and hardware requirements.\n",
    "\n",
    "By documenting and sharing this information, model cards empower all stakeholders to make more informed decisions and foster responsible AI development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a68b9e-9544-4bf7-9538-ea9eeea3fdff",
   "metadata": {},
   "source": [
    "## Explainable and interpretable AI\n",
    "\n",
    "As machine learning systems become more complex, it becomes increasingly important to understand why a model makes a particular decision. This is where Explainable AI (XAI) and Interpretable AI come into play.\n",
    "\n",
    "#### Key Differences\n",
    "**Explainable AI**\n",
    "- Develops post hoc explanations for complex or \"black box\" models (e.g., deep neural networks).\n",
    "- Example: In image classification, an XAI tool might highlight regions of an image that contributed most to the prediction (e.g., saliency maps or heatmaps).\n",
    "\n",
    "**Interpretable AI**\n",
    "- Focuses on building models that are inherently understandable by humans. These models are transparent by design—examples include decision trees, linear models, or rule-based systems.\n",
    "\n",
    "#### Desirable Qualities for Modern Explanations\n",
    "To be effective, modern explanation methods should aim for:\n",
    "- **Soundness and completeness:** The explanation must be faithful to the actual behavior of the model and not oversimplify.\n",
    "- **Computational tractability:** It must be feasible to generate the explanation without excessive computing resources.\n",
    "- **Cognitive tractability:** The explanation should be understandable by humans, ideally non-experts, without requiring deep technical knowledge.\n",
    "\n",
    "#### Characteristics of Interpretable AI\n",
    "Interpretable AI models often aim for simplicity and transparency. Key features include: \n",
    "- **Sparsity:** The model uses as few features or rules as possible (aligned with Occam’s Razor) to offer clear, concise reasoning.\n",
    "- **Monotonicity:** Ensures that relationships between inputs and outputs behave in expected ways (e.g., increasing income should not decrease a credit score).\n",
    "- **Modularity:** The ability to break a model into interpretable components that can be understood individually.\n",
    "- **Linearity:** Using linear relationships where possible makes the model easier to reason about.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BaseGPU",
   "language": "python",
   "name": "basegpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
